import os
import json
import requests
import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
import mlflow.pyfunc
from typing import Dict, Any
from langgraph.graph import StateGraph, END
from app.utils.stock_data import get_stock_technical_data, get_stock_news
from app.utils.llm_handler import generate_llm_response
from app.utils.rag_handler import retrieve_relevant_info
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import feedparser

def fetch_additional_context_from_RAG(state: Dict[str, Any]) -> Dict[str, Any]:
    stock_code = state.get("stock_code")
    model_prediction = state.get("model_prediction", "æ¨è«–çµæœãªã—")

    query = f"{stock_code} {model_prediction}"
    relevant_info = retrieve_relevant_info(query=query, top_k=3)

    prompt = f"""
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã«è©³ã—ã„æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®è¿½åŠ æƒ…å ±ã‚’èª­ã¿ã€çŸ­æœŸæŠ•è³‡ã«å½±éŸ¿ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

    ### ã€è¿½åŠ æƒ…å ±ã€‘
    {relevant_info}

    ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - ã€è¿½åŠ åˆ†æçµæœã€‘ç°¡æ½”ãªè¦ç´„
    - ã€ãƒªã‚¹ã‚¯ãƒ»æ³¨æ„ç‚¹ã€‘çŸ­æœŸæŠ•è³‡ã«ãŠã‘ã‚‹ãƒªã‚¹ã‚¯è¦å› ã‚’è¨˜è¼‰
    """

    additional_summary = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æŒ‡å®š
        user_id="agent1"
    )

    state["additional_summary"] = additional_summary
    return state

# ãƒ‡ãƒãƒƒã‚°ç”¨é–¢æ•°
def debug_print(title, data):
    print(f"\n=== {title} ===")
    print(data)

# ğŸ”¹ Google News RSS ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
def google_news_search(query: str):
    url = f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    
    articles = []
    for entry in feed.entries[:10]:  # æœ€æ–°ã®3ä»¶ã‚’å–å¾—
        articles.append(f"{entry.title}: {entry.link}")
    
    return "\n".join(articles) if articles else "è¿½åŠ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"


def summarize_technical_analysis(state: Dict[str, Any]) -> Dict[str, Any]:
    print(f"\nğŸ“Œ {state['stock_code']} ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æé–‹å§‹...")
    stock_data = state.get("technical_data", pd.DataFrame())
    if stock_data is None or stock_data.empty:
        print(f"âš ï¸ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {state['stock_code']}")
        return {**state, "technical_summary": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}
    
    latest_data = stock_data.iloc[-1]
    prompt = f"""
    ã‚ãªãŸã¯æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã«åŸºã¥ãã€ã“ã®éŠ˜æŸ„ã®çŸ­æœŸæŠ•è³‡åˆ¤æ–­ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

    ### ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã€‘
    - **5æ—¥ç§»å‹•å¹³å‡ç·š**: {latest_data['SMA_5']:.2f}
    - **10æ—¥ç§»å‹•å¹³å‡ç·š**: {latest_data['SMA_10']:.2f}
    - **20æ—¥ç§»å‹•å¹³å‡ç·š**: {latest_data['SMA_20']:.2f}
    - **RSI (ç›¸å¯¾åŠ›æŒ‡æ•°)**: {latest_data['RSI']:.2f}
    - **MACD**: {latest_data['MACD']:.2f}
    - **ATR (ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™)**: {latest_data['ATR']:.2f}

    ### ã€ã‚¿ã‚¹ã‚¯ã€‘
    1. çŸ­æœŸã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ï¼ˆä¸Šæ˜‡ãƒ»ä¸‹è½ãƒ»æ¨ªã°ã„ï¼‰ã€‚
    2. æŒ‡æ¨™ã®çµ„ã¿åˆã‚ã›ã‹ã‚‰ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æ¨å¥¨ã‚’ã—ã¦ãã ã•ã„ã€‚

    ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - ã€çŸ­æœŸæŠ•è³‡åˆ¤æ–­ã€‘ä¸Šæ˜‡å‚¾å‘ / ä¸‹è½å‚¾å‘ / æ¨ªã°ã„
    - ã€ç†ç”±ã€‘ç°¡æ½”ã«èª¬æ˜
    - ã€ãƒªã‚¹ã‚¯è¦å› ã€‘å¤‰å‹•è¦å› ã‚’è¨˜è¼‰
    """
    technical_summary = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æŒ‡å®š
        user_id="agent1"
    )

    print("=== ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æçµæœ ===")
    print(technical_summary)
    return {**state, "technical_summary": technical_summary}

# --------------------------------------------------
# ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸è¶³æ™‚ã€‘ã« google_news_search ã‚’åˆ©ç”¨ã—ã¦è¿½åŠ æƒ…å ±å–å¾—
def react_based_news_analysis(state: Dict[str, Any]) -> Dict[str, Any]:
    ticker = state["stock_code"]
    news_summary = state.get("news_summary", "")
    if "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ" in news_summary or len(news_summary) < 100:
        print(f"âš ï¸ {ticker} ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚è¿½åŠ å–å¾—ã‚’è©¦ã¿ã¾ã™ã€‚")
        additional_news = google_news_search(ticker)
        prompt = f"""
        ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã¯æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™:
        
        ã€ç¾åœ¨ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã€‘:
        {news_summary}

        ã€è¿½åŠ ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘:
        {additional_news}

        è¿½åŠ æƒ…å ±ã‚’è€ƒæ…®ã—ã¦ã€æœ€çµ‚çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’å†è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

        ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
        - ã€ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€‘ãƒã‚¸ãƒ†ã‚£ãƒ– / ãƒã‚¬ãƒ†ã‚£ãƒ– / ä¸­ç«‹
        - ã€ç†ç”±ã€‘ç°¡æ½”ã«èª¬æ˜
        - ã€ãƒªã‚¹ã‚¯è¦å› ã€‘è€ƒæ…®ã™ã¹ããƒã‚¤ãƒ³ãƒˆ
        """
        updated_news = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æŒ‡å®š
        user_id="agent1"
    )

        return {**state, "news_summary": updated_news}
    return state

def summarize_news(state: Dict[str, Any]) -> Dict[str, Any]:
    # get_stock_news() ã«ã‚ˆã‚Šãƒ‹ãƒ¥ãƒ¼ã‚¹åŸæ–‡ã‚’å–å¾—
    ticker = state["stock_code"]
    combined_news = get_stock_news(ticker)
    prompt = f"""
    ã‚ãªãŸã¯æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®ä¼æ¥­ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«åŸºã¥ãã€å¸‚å ´ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

    ### ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¦‚è¦ã€‘
    {combined_news}

    ### ã€ã‚¿ã‚¹ã‚¯ã€‘
    1. ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
    2. ã“ã‚Œã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒçŸ­æœŸçš„ãªæ ªä¾¡å¤‰å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

    ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - ã€ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€‘ãƒã‚¸ãƒ†ã‚£ãƒ– / ãƒã‚¬ãƒ†ã‚£ãƒ– / ä¸­ç«‹
    - ã€ç†ç”±ã€‘ç°¡æ½”ã«èª¬æ˜
    - ã€ãƒªã‚¹ã‚¯è¦å› ã€‘è€ƒæ…®ã™ã¹ãè¦ç´ 
    """
    news_summary = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",
        user_id="agent1"
    )

    print("=== ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æçµæœ ===")
    print(news_summary)
    return {**state, "news_summary": news_summary}

def final_investment_evaluation(state: Dict[str, Any]) -> Dict[str, Any]:
    technical_summary = state.get("technical_summary", "ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†ææƒ…å ±ãªã—")
    news_summary = state.get("news_summary", "ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãªã—")
    model_pred = state.get("model_prediction", "ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ãªã—")
    additional_context = state.get("additional_summary", "è¿½åŠ æƒ…å ±ãªã—")

    prompt = f"""
    ã‚ãªãŸã¯çµŒé¨“è±Šå¯ŒãªæŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€çŸ­æœŸæŠ•è³‡è©•ä¾¡ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

    ### ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æçµæœã€‘
    {technical_summary}

    ### ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æçµæœã€‘
    {news_summary}

    ### ã€ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬çµæœã€‘
    {model_pred}

    ### ã€è¿½åŠ ã®å‚è€ƒæƒ…å ±ï¼ˆRAGï¼‰ã€‘
    {additional_context}

    ### ã€ã‚¿ã‚¹ã‚¯ã€‘
    1. çŸ­æœŸæŠ•è³‡è©•ä¾¡ã‚’10æ®µéšã‚¹ã‚³ã‚¢ï¼ˆ1: éå¸¸ã«æ‚ªã„ ã€œ 10: éå¸¸ã«è‰¯ã„ï¼‰ã§æç¤ºã—ã¦ãã ã•ã„ã€‚
    2. ãã®ç†ç”±ã¨çŸ­æœŸãƒªã‚¹ã‚¯è¦å› ã‚’ç°¡æ½”ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

    ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - ã€çŸ­æœŸæŠ•è³‡è©•ä¾¡ã€‘ã‚¹ã‚³ã‚¢
    - ã€ç†ç”±ã€‘
    - ã€ãƒªã‚¹ã‚¯è¦å› ã€‘
    """
    final_eval = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æŒ‡å®š
        user_id="agent1"
    )

    print("=== æœ€çµ‚æŠ•è³‡è©•ä¾¡ ===")
    print(final_eval)
    return {**state, "final_evaluation": final_eval}

def reflect_on_evaluation(state: Dict[str, Any]) -> Dict[str, Any]:
    # Reflectionã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§æœ€çµ‚è©•ä¾¡çµæœã®å†æ¤œè¨ã‚’è¡Œã†
    original_eval = state.get("final_evaluation", "")
    prompt = f"""
    ã‚ãªãŸã¯ç†Ÿç·´ã®æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã¯å…ˆã»ã©ã®çŸ­æœŸæŠ•è³‡è©•ä¾¡ã§ã™ã€‚ã“ã‚Œã‚’è¸ã¾ãˆã€ã•ã‚‰ã«æ¤œè¨ã—ã¦ã€è©•ä¾¡ã®å¦¥å½“æ€§ã‚„è£œè¶³ã™ã¹ããƒªã‚¹ã‚¯è¦å› ãŒã‚ã‚Œã°å†è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

    ### ã€å…ƒã®çŸ­æœŸæŠ•è³‡è©•ä¾¡ã€‘
    {original_eval}

    ### ã€ã‚¿ã‚¹ã‚¯ã€‘
    1. å…ƒã®è©•ä¾¡ã«åŸºã¥ã„ã¦ã€è©•ä¾¡ã®æ”¹å–„ç‚¹ãŒã‚ã‚Œã°å…·ä½“çš„ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
    2. å¿…è¦ã§ã‚ã‚Œã°ã€è©•ä¾¡ã‚’ä¿®æ­£ã—ã€å†è©•ä¾¡ã®çµæœã‚’10æ®µéšã‚¹ã‚³ã‚¢ã§ç¤ºã—ã¦ãã ã•ã„ã€‚
    3. è£œè¶³ã®ç†ç”±ã‚„ãƒªã‚¹ã‚¯è¦å› ã‚‚è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

    ### ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - ã€å†è©•ä¾¡çŸ­æœŸæŠ•è³‡è©•ä¾¡ã€‘ã‚¹ã‚³ã‚¢ï¼ˆ1ã€œ10ï¼‰

    - ã€è©•ä¾¡ç†ç”±ã€‘è©³ç´°ãªèª¬æ˜

    - ã€è£œè¶³ãƒªã‚¹ã‚¯è¦å› ã€‘è€ƒæ…®ã™ã¹ããƒã‚¤ãƒ³ãƒˆ

    **â€»å‡ºåŠ›ã¯ã€èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«é©åˆ‡ãªæ”¹è¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚**

    """
    reflection = generate_llm_response(
        prompt,
        model_name="gemini-1.5-flash",
        prompt_template_version="v2.3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æŒ‡å®š
        user_id="agent1"
    )

    print("=== å†è©•ä¾¡ï¼ˆReflectionï¼‰ ===")
    print(reflection)
    return {**state, "final_evaluation": reflection}

############################
# â‘  MLflow Tracking/Models/Registry ã®è¨­å®šï¼ˆæ—¢å­˜éƒ¨åˆ†ï¼‰
############################

# MLflow ã® Tracking URI ã¨ Artifact URI ã‚’ Tracking ç”¨ã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®šã«åˆã‚ã›ã‚‹
os.environ["MLFLOW_TRACKING_URI"] = "http://mlflow-tracking:5003"
#os.environ["MLFLOW_ARTIFACT_URI"] = "models:/Stock_Chart_Classification_Model/Production"
os.environ["MLFLOW_ARTIFACT_URI"] = "/app/mlflow-tracking/artifacts"
mlflow.set_tracking_uri(os.environ["MLFLOW_TRACKING_URI"])

print("MLFLOW_TRACKING_URI:", os.getenv("MLFLOW_TRACKING_URI"))
print("MLFLOW_ARTIFACT_URI:", os.getenv("MLFLOW_ARTIFACT_URI"))

client = mlflow.tracking.MlflowClient()
experiment_name = "Stock_Chart_Classification_3"
experiment = client.get_experiment_by_name(experiment_name)
if experiment is None:
    experiment_id = client.create_experiment(
        name=experiment_name,
        artifact_location=os.getenv("MLFLOW_ARTIFACT_URI")
    )
    print(f"æ–°ã—ã„ Experiment '{experiment_name}' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
else:
    experiment_id = experiment.experiment_id
    print(f"æ—¢å­˜ã® Experiment '{experiment_name}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
mlflow.set_experiment(experiment_name)

############################
# â‘¢ æ–°ãŸã«è¿½åŠ ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼šMLflow ã«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ä¸­ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–
############################

# æ•°å€¤ãƒ©ãƒ™ãƒ«ã¨ã‚«ãƒ†ã‚´ãƒªåã®å¯¾å¿œã‚’è¾æ›¸ã¨ã—ã¦å®šç¾©
category_mapping = {
    0: "ã“ã‚Œã‹ã‚‰ä¸Šæ˜‡ï¼Ÿ", 1: "ã—ã£ã‹ã‚Š?", 2: "ãã‚ãã‚å¤©äº•?", 3: "ã¾ã ä¸Šæ˜‡?",
    4: "ã¾ã ä¸‹è½?", 5: "ã‚‚ã¿åˆã„?", 6: "ãƒªãƒã‚¦ãƒ³ãƒ‰?", 7: "ä¸Šæ˜‡?",
    8: "ä¸Šæ˜‡ã‚¹ãƒˆãƒƒãƒ—ï¼Ÿ", 9: "ä¸Šæ˜‡ä¸€æœ?", 10: "ä¸Šæ˜‡åŸºèª¿?", 11: "ä¸‹ã’ã¨ã¾ã£ãŸï¼Ÿ",
    12: "ä¸‹ã’æ¸‹ã‚‹?", 13: "ä¸‹æŠ¼ã™?", 14: "ä¸‹è½?", 15: "ä¸‹è½ã‚¹ãƒˆãƒƒãƒ—ï¼Ÿ",
    16: "ä¸‹è½åŸºèª¿?", 17: "å£²ã‚Šï¼Ÿ", 18: "å¼±å«ã¿?", 19: "å¼·å«ã¿?",
    20: "æ€¥ä¸Šæ˜‡?", 21: "æ€¥è½?", 22: "æˆ»ã£ã¦ãã‚‹ï¼Ÿ", 23: "æˆ»ã‚‰ãªã„ï¼Ÿ",
    24: "è¡Œã£ã¦æ¥ã„?"
}

def predict_stock_category(processed_df: pd.DataFrame) -> str:
    """
    processed_df ã¯å„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ç‰¹å¾´é‡ã‚’å«ã‚€ DataFrameï¼ˆä¾‹ï¼šã‚«ãƒ©ãƒ ã¯
    ["Ticker", "Category", "all_é¨°è½ç‡", "avg_Volume", "Day1_é¨°è½ç‡", ..., "Day22_é¨°è½ç‡"]ï¼‰ã§ã‚ã‚‹ã¨ä»®å®šã€‚
    ãƒ¢ãƒ‡ãƒ«ã«ã¯ Ticker, Category ä»¥å¤–ã®æ•°å€¤ç‰¹å¾´é‡ã‚’å…¥åŠ›ã™ã‚‹ã¨æƒ³å®šã€‚
    """
    # æ¨è«–ã«å¿…è¦ãªç‰¹å¾´é‡ã ã‘æŠ½å‡ºï¼ˆä¾‹ï¼šTicker, Categoryã¯é™¤ãï¼‰
    feature_columns = [col for col in processed_df.columns if col not in ["Ticker","Category"]]
#    if "Category" in processed_df.columns:
#        processed_df["Category"] = pd.to_numeric(processed_df["Category"], errors="coerce").fillna(1)
    input_df = processed_df[feature_columns]
#    print("å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡:", model.metadata.get_input_schema())
    print("ç¾åœ¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡:", input_df.columns.tolist())

    # **MLflow ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰**
    model_uri = "models:/Stock_Chart_Classification_Model/Production"  # é©å®œå¤‰æ›´
    model = None  # åˆæœŸåŒ–
    try:
        print(f"ğŸ”„ MLflow ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_uri}")
        model = mlflow.pyfunc.load_model(model_uri)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")

        # **ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ãŸå¾Œã«ç‰¹å¾´é‡ã‚’è¡¨ç¤º**
        print("å­¦ç¿’æ™‚ã®ç‰¹å¾´é‡:", model.metadata.get_input_schema())

    except Exception as e:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:", e)
        raise Exception(f"Model loading failed: {str(e)}")

    # **ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿äºˆæ¸¬ã‚’è¡Œã†**
    if model is None:
        raise ValueError("âŒ ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚MLflow ã‹ã‚‰æ­£ã—ãå–å¾—ã§ãã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # **ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–**
    try:
        predictions = model.predict(input_df)
        # **äºˆæ¸¬çµæœã‚’æ•°å€¤ãƒ©ãƒ™ãƒ«ã‹ã‚‰æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã«å¤‰æ›**
        predictions_mapped = [category_mapping.get(int(pred), "æœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒª") for pred in predictions]
        processed_df["Prediction"] = predictions_mapped
        print("âœ… ãƒ¢ãƒ‡ãƒ«æ¨è«–æˆåŠŸ:", predictions_mapped)
        return predictions_mapped[0]  # ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã•ãšã€ãƒªã‚¹ãƒˆã®ã¿è¿”ã™

#        predictions = model.predict(input_df)
#        processed_df["Prediction"] = predictions
#        print("âœ… ãƒ¢ãƒ‡ãƒ«æ¨è«–æˆåŠŸ:", predictions)
#        return processed_df
    except Exception as e:
        print("âŒ ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚¨ãƒ©ãƒ¼:", e)
        raise Exception(f"Model inference failed: {str(e)}")

def model_inference_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    LangGraph ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å†…ã®ãƒãƒ¼ãƒ‰ã¨ã—ã¦ã€state ã«
    "processed_data"ï¼ˆpandas DataFrameï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‰æã§ã€ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
    æ¨è«–çµæœã¯ state["model_prediction"] ã«æ ¼ç´ã™ã‚‹ã€‚
    """
    processed_data = state.get("processed_data")
    if processed_data is None or processed_data.empty:
        print("äºˆæ¸¬å¯¾è±¡ã® processed_data ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        state["model_prediction"] = None
        return state

    try:
        prediction_df = predict_stock_category(processed_data)
        state["model_prediction"] = prediction_df
        print("âœ… æ¨è«–çµæœã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        state["model_prediction"] = str(e)
        print("æ¨è«–ã‚¨ãƒ©ãƒ¼:", e)
    return state

# --------------------------------------------------
# ã€processed_dataã€‘ç”Ÿæˆãƒãƒ¼ãƒ‰ï¼ˆtechnical_dataã‹ã‚‰å˜ç´”ã‚³ãƒ”ãƒ¼ä¾‹ï¼‰
def create_processed_data(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    1. Yahoo Financeã‹ã‚‰æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—DataFrameåŒ–ã™ã‚‹ï¼ˆget_stock_technical_data() ã‚’åˆ©ç”¨ï¼‰
    2. DataFrameã‹ã‚‰ç‰¹å¾´é‡ã‚’ç”Ÿæˆã™ã‚‹
       - é¨°è½ç‡(Return)ã®è¨ˆç®—
       - å…¨ä½“ã®é¨°è½ç‡ (all_é¨°è½ç‡)
       - å¹³å‡å‡ºæ¥é«˜ (avg_Volume)
       - å„æ—¥ï¼ˆDay1_ï½Day22_é¨°è½ç‡ï¼‰ã®é¨°è½ç‡
       â€» Category ã¯ state ã« "category" ã‚­ãƒ¼ãŒã‚ã‚Œã°åˆ©ç”¨ã—ã€ãªã‘ã‚Œã° "Unknown"
    3. ç”Ÿæˆã—ãŸç‰¹å¾´é‡ã®1è¡Œ DataFrame ã‚’å…ƒã«ã€MLflow ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆStockCategoryModel ã® Production ã‚¹ãƒ†ãƒ¼ã‚¸ï¼‰ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ­ãƒ¼ãƒ‰ã—ã¦äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹
    4. äºˆæ¸¬çµæœï¼ˆä¾‹ï¼šãƒãƒ£ãƒ¼ãƒˆæƒ…å ±ãªã©ï¼‰ã‚’ state["model_prediction"] ã«æ ¼ç´ã—ã¦è¿”ã™
    """
    import pandas as pd
    ticker = state.get("stock_code")
    if not ticker:
        print("Error: 'stock_code' ãŒ state ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        state["processed_data"] = pd.DataFrame()
        state["model_prediction"] = None
        return state

    # --- 1. ãƒ‡ãƒ¼ã‚¿ã®å–å¾— ---
    stock_data = get_stock_technical_data(ticker)
    if stock_data is None or stock_data.empty:
        print(f"æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {ticker}")
        state["processed_data"] = pd.DataFrame()
        state["model_prediction"] = None
        return state

    # --- 2. ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ï¼ˆç‰¹å¾´é‡ç”Ÿæˆï¼‰ ---
    # é¨°è½ç‡ã®è¨ˆç®—
    stock_data['Return'] = stock_data['Close'].pct_change()
    # 1è¡Œç›®ã¯ NaN ã¨ãªã‚‹ãŸã‚ã€ä»¥é™ã®å€¤ã‚’ãƒªã‚¹ãƒˆåŒ–ï¼ˆä¾‹ï¼šDay1ï½DayN ã®é¨°è½ç‡ï¼‰
    return_rates = stock_data['Return'].iloc[1:].tolist()
    # å…¨ä½“ã®é¨°è½ç‡ï¼šåˆå€¤ã‹ã‚‰æœ€çµ‚å€¤ã¾ã§ã®å¤‰åŒ–ç‡
    all_return_rate = (stock_data['Close'].iloc[-1] / stock_data['Close'].iloc[0]) - 1

    # ç‰¹å¾´é‡ã®ç”Ÿæˆ
    processed_data = pd.DataFrame({
        'Ticker': [ticker],
        'Category': [state.get('category', 'Unknown')],
        'all_é¨°è½ç‡': [all_return_rate],
        'avg_Volume': [stock_data['Volume'].mean()]
    })

    # å„æ—¥ã®é¨°è½ç‡ã‚’è¿½åŠ 
    for i, rate in enumerate(return_rates[:22], 1):  # æœ€å¤§22æ—¥åˆ†
        processed_data[f'Day{i}_é¨°è½ç‡'] = [rate]

    state["processed_data"] = processed_data
    return state

# LangGraph ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰
graph = StateGraph(Dict[str, Any])
graph.add_node("fetch_technical_data", lambda state: {**state, "technical_data": get_stock_technical_data(state["stock_code"])})
graph.add_node("summarize_technical_analysis", summarize_technical_analysis)
graph.add_node("summarize_news", summarize_news)
graph.add_node("react_based_news_analysis", react_based_news_analysis)
graph.add_node("create_processed_data", create_processed_data)
graph.add_node("model_inference", model_inference_node)
graph.add_node("fetch_additional_context_from_RAG", fetch_additional_context_from_RAG)
graph.add_node("final_investment_evaluation", final_investment_evaluation)
graph.add_node("reflect_on_evaluation", reflect_on_evaluation)

graph.set_entry_point("fetch_technical_data")
graph.add_edge("fetch_technical_data", "summarize_technical_analysis")
graph.add_edge("summarize_technical_analysis", "summarize_news")
graph.add_edge("summarize_news", "react_based_news_analysis")
graph.add_edge("react_based_news_analysis", "create_processed_data")
graph.add_edge("create_processed_data", "model_inference")
graph.add_edge("model_inference", "fetch_additional_context_from_RAG")
graph.add_edge("fetch_additional_context_from_RAG", "final_investment_evaluation")
graph.add_edge("final_investment_evaluation", "reflect_on_evaluation")
graph.add_edge("reflect_on_evaluation", END)


# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”Ÿæˆ
short_term_agent = graph.compile()

def run_short_term_analysis_v3(stock_code: str):
    initial_state = {"stock_code": stock_code}
    result = short_term_agent.invoke(initial_state)
    # æœ€çµ‚è©•ä¾¡ï¼ˆLLM ã«ã‚ˆã‚‹è©•ä¾¡ï¼‰ã¨ã¨ã‚‚ã«ã€ãƒ¢ãƒ‡ãƒ«æ¨è«–çµæœã‚‚å–å¾—
    final_eval = result.get("final_evaluation", "è©•ä¾¡ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    model_pred = result.get("model_prediction", "æ¨è«–çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return final_eval, model_pred
