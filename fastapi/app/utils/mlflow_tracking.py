import mlflow
import os
import subprocess

# ğŸ“Œ **MLflow ã®è¨­å®š**
mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))
MLFLOW_EXPERIMENT_NAME = "LLM_Tracking_"
mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)

# ğŸš€ FastAPIã‚³ãƒ³ãƒ†ãƒŠã§ã¯ `/app` ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = "/app"

# ğŸ“Œ **Git ã®æƒ…å ±ã‚’å–å¾—**
def get_git_commit_hash():
    """ç¾åœ¨ã® Git ã®ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
    try:
#        repo = git.Repo(PROJECT_ROOT, search_parent_directories=True)
#        return repo.head.object.hexsha
        return subprocess.check_output(["git", "rev-parse", "HEAD"]).strip().decode("utf-8")
    except Exception:
        return "unknown"

def get_git_branch():
    """ç¾åœ¨ã® Git ã®ãƒ–ãƒ©ãƒ³ãƒåã‚’å–å¾—"""
    try:
        return subprocess.check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"]).strip().decode("utf-8")
#        repo = git.Repo(PROJECT_ROOT, search_parent_directories=True)
#        return repo.active_branch.name
    except Exception:
        return "unknown"

def track_llm_response(prompt: str, response: str, model_name="gemini-1.5-flash"):
    """ LLM ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ MLflow ã«è¨˜éŒ² """
    with mlflow.start_run(nested=True):  # âœ… å¤‰æ›´: nested=True ã‚’çµ±ä¸€
        # ğŸ”¹ Git ã®æƒ…å ±ã‚’ MLflow ã«è¨˜éŒ²
        git_commit = get_git_commit_hash()
        git_branch = get_git_branch()
        
        mlflow.set_tag("git_commit", git_commit)
        mlflow.set_tag("git_branch", git_branch)
        mlflow.set_tag("model_name", model_name)
        mlflow.set_tag("task", "llm_analysis")
        # ä¾‹: llm_handler.py ã® generate_llm_response å†…
        snippet_length = 100  # é©å®œèª¿æ•´
        snippet = prompt[:snippet_length] + ("..." if len(prompt) > snippet_length else "")

        # âœ… `log_param()` ã‚‚ä½¿ç”¨ã—ã¦ Parameters ã«è¡¨ç¤ºã•ã›ã‚‹
        mlflow.log_param("git_commit", git_commit)
        mlflow.log_param("git_branch", git_branch)
        mlflow.log_param("model_name", model_name)
        mlflow.log_param("task", "llm_analysis")
        mlflow.log_param("prompt_snippet", snippet)  # Parameters ã‚¿ãƒ–ç”¨ï¼ˆçŸ­ã„æŠœç²‹ï¼‰

        mlflow.log_text(prompt, "prompt.txt")
        mlflow.log_text(response, "response.txt")

        mlflow.end_run()
